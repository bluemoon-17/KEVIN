## ğŸ’» ë”¥ëŸ¬ë‹ í•µì‹¬ ê°œë… ì •ë¦¬ (2ì£¼ì°¨ ~ 7ì£¼ì°¨ ì „ì²´ ìš”ì•½)

### 2ì£¼ì°¨: ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ ë° ë°ì´í„° ì •ì˜

| ì£¼ì œ | í•µì‹¬ ê°œë… | ì„¤ëª… (ì •ì˜/ì˜ë¯¸) |
| :--- | :--- | :--- |
| **ì¸ê³µì§€ëŠ¥ ê³„ì¸µ** | **ë”¥ëŸ¬ë‹ (DL)** | **ì •ì˜:** **ì‹¬ì¸µ ì‹ ê²½ë§(Deep Neural Network)**ì„ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜. (AI âŠƒ ML âŠƒ DL) |
| **ì¸ê³µì§€ëŠ¥ ê³„ì¸µ** | **ë¨¸ì‹ ëŸ¬ë‹ (ML)** | **ì •ì˜:** ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ìŠ¤ìŠ¤ë¡œ í•™ìŠµ**í•˜ì—¬ ì„±ëŠ¥ì„ ë°˜ë³µì ìœ¼ë¡œ ê°œì„ í•´ë‚˜ê°€ëŠ” ì»´í“¨í„° ì•Œê³ ë¦¬ì¦˜. |
| **í•™ìŠµ ìœ í˜•** | **ì§€ë„ í•™ìŠµ** | **ì˜ë¯¸:** ì…ë ¥ ë°ì´í„°($X$)ì™€ **ì •ë‹µ ë ˆì´ë¸”($Y$)**ì„ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ë°©ì‹. |
| **í•™ìŠµ ìœ í˜•** | **ë¹„ì§€ë„ í•™ìŠµ** | **ì˜ë¯¸:** ì •ë‹µ(ë ˆì´ë¸”) ì—†ì´ ì…ë ¥ ë°ì´í„°($X$)ë§Œìœ¼ë¡œ ë°ì´í„°ì˜ **ë‚´ì¬ëœ êµ¬ì¡°ë‚˜ íŒ¨í„´**ì„ ìŠ¤ìŠ¤ë¡œ ë°œê²¬í•˜ì—¬ í•™ìŠµí•˜ëŠ” ë°©ì‹. |
| **ë°ì´í„° ë³€ìˆ˜** | **ë…ë¦½ ë³€ìˆ˜ (Independent Variable)** | **ì •ì˜:** ëª¨ë¸ì˜ **ì…ë ¥ê°’**ìœ¼ë¡œ ì‚¬ìš©ë˜ë©° ì¢…ì† ë³€ìˆ˜ì— ì˜í–¥ì„ ì£¼ëŠ” ë³€ìˆ˜. |

---

### 3ì£¼ì°¨: í…ì„œ, ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ (K-NN, SVM)

| ì£¼ì œ | í•µì‹¬ ê°œë… | ì„¤ëª… (ì •ì˜/ì˜ë¯¸) |
| :--- | :--- | :--- |
| **ë°ì´í„° êµ¬ì¡°** | **í…ì„œ (Tensor)** | **ì •ì˜:** ë”¥ëŸ¬ë‹ì—ì„œ ë°ì´í„°ë¥¼ í‘œí˜„í•˜ëŠ” ê¸°ë³¸ ë‹¨ìœ„ë¡œ, **3ì°¨ì› ì´ìƒì˜ ë°°ì—´** í˜•íƒœë¥¼ ê°€ì§. |
| **ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬** | **í…ì„œí”Œë¡œ (TensorFlow)** | **ì •ì˜:** ë°ì´í„° íë¦„ ê·¸ë˜í”„ë¥¼ ì‚¬ìš©í•˜ì—¬ **í…ì„œì˜ ìˆ˜ì¹˜ ì—°ì‚°ì„ ìˆ˜í–‰**í•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬. |
| **ë°ì´í„° ì „ì²˜ë¦¬** | **ì›-í•« ì¸ì½”ë”©** | **ëª©ì :** **ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ìˆ«ì ë²¡í„°**ë¡œ ë³€í™˜í•˜ì—¬ ì‹ ê²½ë§ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ë°©ì‹. |
| **ì§€ë„ í•™ìŠµ** | **K-NN (K-ìµœê·¼ì ‘ ì´ì›ƒ)** | **ì •ì˜:** **ê²Œìœ¼ë¥¸ í•™ìŠµì(Lazy Learner)** ê¸°ë°˜. ìƒˆë¡œìš´ ë°ì´í„°ì™€ **ê°€ì¥ ê°€ê¹Œìš´ Kê°œ ì´ì›ƒ**ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜. |
| **ì§€ë„ í•™ìŠµ** | **SVM (ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ )** | **ì •ì˜:** ë‘ í´ë˜ìŠ¤ ì‚¬ì´ì˜ **ë§ˆì§„(ê±°ë¦¬)ì„ ìµœëŒ€í™”**í•˜ëŠ” **ì´ˆí‰ë©´**ì„ ì°¾ì•„ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜. |

---

### 4ì£¼ì°¨: ë¨¸ì‹ ëŸ¬ë‹ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ (Decision Tree, Regression)

| ì£¼ì œ | í•µì‹¬ ê°œë… | ì„¤ëª… (ì •ì˜/ì˜ë¯¸) |
| :--- | :--- | :--- |
| **ì§€ë„ í•™ìŠµ** | **ê²°ì • íŠ¸ë¦¬ (Decision Tree)** | **ì •ì˜:** ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì§ˆë¬¸(ì¡°ê±´)ìœ¼ë¡œ ë¶„ê¸°í•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ ë¶„ë¥˜ ë˜ëŠ” ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” **íŠ¸ë¦¬ êµ¬ì¡°** ëª¨ë¸. |
| **ê²°ì • íŠ¸ë¦¬** | **ì •ë³´ ì´ë“ (Information Gain)** | **ì •ì˜:** ë…¸ë“œë¥¼ ë¶„í• í•˜ê¸° ì „í›„ì˜ **ë¶ˆìˆœë„ ê°ì†ŒëŸ‰**. ì´ ê°’ì´ **ìµœëŒ€**ê°€ ë˜ë„ë¡ ë…¸ë“œ ë¶„í•  ê¸°ì¤€ì„ ì„ íƒí•©ë‹ˆë‹¤. |
| **ì§€ë„ í•™ìŠµ** | **ë¡œì§€ìŠ¤í‹± íšŒê·€** | **ì •ì˜:** **ë¶„ë¥˜** ëª¨ë¸. ì„ í˜• íšŒê·€ ê²°ê³¼ë¥¼ **ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜**ì— ì ìš©í•˜ì—¬ ì¶œë ¥ê°’ì„ **0ê³¼ 1 ì‚¬ì´ì˜ í™•ë¥ **ë¡œ ë³€í™˜í•´ ì´ì§„ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰. |
| **ì§€ë„ í•™ìŠµ** | **ì„ í˜• íšŒê·€ (Linear Regression)** | **ì •ì˜:** **íšŒê·€** ëª¨ë¸. ë…ë¦½ ë³€ìˆ˜ì™€ ì¢…ì† ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ **ìµœì ì˜ ì§ì„ **ìœ¼ë¡œ ëª¨ë¸ë§í•˜ì—¬ ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡í•˜ê³  ì„¤ëª…. |

---

### 5ì£¼ì°¨: ë”¥ëŸ¬ë‹ ê¸°ë³¸ ìš”ì†Œì™€ ìµœì í™” ë° ë¹„ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜

| ì£¼ì œ | í•µì‹¬ ê°œë… | ì„¤ëª… (ì •ì˜/ì˜ë¯¸) |
| :--- | :--- | :--- |
| **ì‹ ê²½ë§ ìš”ì†Œ** | **í™œì„±í™” í•¨ìˆ˜** | **ì˜ë¯¸:** ë‰´ëŸ°ì˜ ì¶œë ¥ ì‹ í˜¸ë¥¼ ê²°ì •í•˜ê³ , ë”¥ëŸ¬ë‹ ëª¨ë¸ì— **ë¹„ì„ í˜•ì„±**ì„ ë„ì…í•˜ì—¬ ë³µì¡í•œ í•¨ìˆ˜ ê·¼ì‚¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•¨. |
| **ì‹ ê²½ë§ ìš”ì†Œ** | **ì†ì‹¤ í•¨ìˆ˜ (Loss Function)** | **ì •ì˜:** ëª¨ë¸ì˜ **ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ì •ë‹µê°’ ì‚¬ì´ì˜ ì˜¤ì°¨**ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜. í•™ìŠµ ëª©í‘œëŠ” ì´ ê°’ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒ. |
| **ìµœì í™” ì•Œê³ ë¦¬ì¦˜** | **ê²½ì‚¬ í•˜ê°•ë²•** | **ëª©ì :** ì†ì‹¤ í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” **ìµœì ì˜ ê°€ì¤‘ì¹˜**ë¥¼ ì°¾ê¸° ìœ„í•´, **ê¸°ìš¸ê¸° ë°˜ëŒ€ ë°©í–¥**ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê°±ì‹ í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜. |
| **ìµœì í™” ê¸°ë²•** | **ëª¨ë©˜í…€ (Momentum)** | **ì˜ë¯¸:** ê²½ì‚¬ í•˜ê°•ë²•ì— **ê´€ì„±** ê°œë…ì„ ë„ì…í•˜ì—¬ í•™ìŠµ ì¤‘ ë°œìƒí•˜ëŠ” ì§€ì—­ ìµœì†Ÿê°’ì— ê°‡íˆëŠ” ê²ƒì„ ë°©ì§€í•˜ê³  ìˆ˜ë ´ ì†ë„ë¥¼ ë†’ì´ëŠ” ê¸°ë²•. |
| **ìµœì í™” ê¸°ë²•** | **NAG (Nesterov Accelerated Gradient)** | **ì˜ë¯¸:** ëª¨ë©˜í…€ ì ìš© í›„ **ë¯¸ë¦¬ ì´ë™í•œ ì§€ì **ì—ì„œ ê¸°ìš¸ê¸°ë¥¼ ì¬ê³„ì‚°í•˜ì—¬ ë” ì •í™•í•˜ê²Œ ìµœì ì ì„ íƒìƒ‰í•˜ëŠ” ê¸°ë²•. |
| **ë¹„ì§€ë„ í•™ìŠµ** | **K-means Clustering** | **ì •ì˜:** ë°ì´í„°ë¥¼ **Kê°œì˜ êµ°ì§‘**ìœ¼ë¡œ ë¬¶ëŠ” êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜. í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì ê³¼ì˜ ê±°ë¦¬ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì¤‘ì‹¬ì ì„ ê°±ì‹ . |
| **ë¹„ì§€ë„ í•™ìŠµ** | **PCA (Principal Component Analysis)** | **ëª©ì :** ë°ì´í„°ì˜ **ì°¨ì› ì¶•ì†Œ** ê¸°ë²•. ë°ì´í„°ì˜ **ë¶„ì‚°ì´ ê°€ì¥ í° ë°©í–¥(ì£¼ì„±ë¶„)**ì„ ì°¾ì•„ ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë©° ë°ì´í„°ë¥¼ ì••ì¶•í•¨. |

---

### 6ì£¼ì°¨: í•©ì„±ê³± ì‹ ê²½ë§ (CNN)ì˜ êµ¬ì„± ìš”ì†Œ

| ì£¼ì œ | í•µì‹¬ ê°œë… | ì„¤ëª… (ì •ì˜/ì˜ë¯¸) |
| :--- | :--- | :--- |
| **CNNì˜ í•„ìš”ì„±** | **ì§€ì—­ì  íŠ¹ì§• ì¶”ì¶œ** | **ì˜ë¯¸:** ì´ë¯¸ì§€ ì „ì²´ê°€ ì•„ë‹Œ ì‘ì€ ë¶€ë¶„ì„ ê³„ì‚°í•˜ì—¬ **ìì› ì†Œëª¨ë¥¼ ì¤„ì´ê³ **, ì´ë¯¸ì§€ì˜ ì—£ì§€, ì§ˆê° ë“± **ì§€ì—­ì  íŠ¹ì§•**ì„ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµí•˜ê¸° ìœ„í•´ CNNì„ ì‚¬ìš©. |
| **CNN êµ¬ì¡°** | **í•©ì„±ê³± ì¸µ (Convolutional Layer)** | **ì •ì˜:** ì…ë ¥ ì´ë¯¸ì§€ì— **í•„í„°(Filter)**ë¥¼ ì ìš©í•˜ì—¬ **íŠ¹ì§• ë§µ(Feature Map)**ì„ ì¶”ì¶œí•˜ëŠ” ì¸µ. |
| **CNN êµ¬ì¡°** | **í•„í„° (Filter / Kernel)** | **ì •ì˜:** í•©ì„±ê³± ì¸µì—ì„œ ì‚¬ìš©ë˜ë©° ì´ë¯¸ì§€ì˜ **ì§€ì—­ì  íŠ¹ì§•ì„ í•™ìŠµ**í•˜ëŠ” ì‘ì€ í–‰ë ¬(ê°€ì¤‘ì¹˜). |
| **CNN êµ¬ì¡°** | **í’€ë§ ì¸µ (Pooling Layer)** | **ëª©ì :** íŠ¹ì§• ë§µì˜ **í¬ê¸°(ì°¨ì›)ë¥¼ ì¤„ì—¬** ê³„ì‚°ëŸ‰ì„ ê°ì†Œì‹œí‚¤ê³ , ë¯¸ì„¸í•œ ìœ„ì¹˜ ë³€í™”ì— ëª¨ë¸ì´ ëœ ë¯¼ê°í•˜ë„ë¡ **ê°•ì¸ì„±**ì„ ë¶€ì—¬í•˜ëŠ” ì¸µ. |
| **CNN ì‘ìš©** | **GCN (Graph Convolutional Network)** | **ì •ì˜:** **ê·¸ë˜í”„ êµ¬ì¡° ë°ì´í„°**(ë…¸ë“œì™€ ì—ì§€)ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì‹ ê²½ë§. ì¸ì ‘ í–‰ë ¬ ë“±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë…¸ë“œì™€ ì£¼ë³€ ë…¸ë“œì˜ ì •ë³´ë¥¼ í•¨ê»˜ í•™ìŠµí•¨. |

---

### 7ì£¼ì°¨: LeNet-5 ë° CNN ì‹¬í™” êµ¬ì¡°

| ì£¼ì œ | í•µì‹¬ ê°œë… | ì„¤ëª… (ì •ì˜/ì˜ë¯¸) |
| :--- | :--- | :--- |
| **ìµœì´ˆì˜ CNN** | **LeNet-5** | **ì •ì˜:** 1995ë…„ **ì–€ ë¥´ì¿¤**ì´ ê°œë°œí•œ **ìµœì´ˆì˜ CNN êµ¬ì¡°**. **í•©ì„±ê³±(C)ê³¼ ë‹¤ìš´ ìƒ˜í”Œë§(S)**ì˜ ë°˜ë³µ êµ¬ì¡°ë¥¼ ì •ë¦½í•¨. |
| **CNN êµ¬ì¡° íŠ¹ì§•** | **ì™„ì „ì—°ê²°ì¸µ (Fully Connected Layer)** | **ì˜ë¯¸:** í•©ì„±ê³±/í’€ë§ ì¸µì—ì„œ ì¶”ì¶œëœ **ëª¨ë“  íŠ¹ì§•**ì„ ë°›ì•„ ìµœì¢…ì ìœ¼ë¡œ **ë¶„ë¥˜(Classification)**ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì‹ ê²½ë§ ì¸µ. |
| **CNN ì‹¬í™”** | **ì”ì°¨ í•™ìŠµ (Residual Learning)** | **ëª©ì :** ë„¤íŠ¸ì›Œí¬ ì¸µì´ ê¹Šì–´ì§ˆ ë•Œ ë°œìƒí•˜ëŠ” **ì„±ëŠ¥ ì €í•˜** ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **ìˆì»·(Skip Connection)**ì„ ë„ì…í•˜ì—¬ í•™ìŠµì„ ìš©ì´í•˜ê²Œ í•˜ëŠ” ë°©ì‹ (ResNetì˜ í•µì‹¬). |
| **CNN ì‹¬í™”** | **ìˆì»· / ìŠ¤í‚µ ì»¤ë„¥ì…˜** | **ì •ì˜:** ResNetì—ì„œ ì‚¬ìš©ë˜ë©°, ì…ë ¥ $x$ë¥¼ í•œ ì¸µ ë˜ëŠ” ë¸”ë¡ì˜ ì¶œë ¥ì— **ë°”ë¡œ ë”í•´ì£¼ëŠ”** ì—°ê²° ê²½ë¡œ. ì”ì°¨ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ì—­ì „íŒŒ ì‹œ ê¸°ìš¸ê¸° ì†Œì‹¤ì„ ë°©ì§€í•¨. |




## ğŸ’» ë”¥ëŸ¬ë‹ ì‘ìš© í”„ë¡œê·¸ë˜ë° í•µì‹¬ ê°œë… ì½”ë“œ ë¶„ì„ (2ì£¼ì°¨ ~ 7ì£¼ì°¨)

# ==============================================================================
# 2ì£¼ì°¨: ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ ë° ë°ì´í„° ì •ì˜
# ==============================================================================

# AI, ML, DL ê³„ì¸µ êµ¬ì¡°
HIERARCHY = "AI âŠƒ ML âŠƒ DL" # # ì£¼ì„: ë”¥ëŸ¬ë‹ì€ ì‹¬ì¸µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ í•˜ìœ„ ì§‘í•©

# ë°ì´í„° ë³€ìˆ˜ ì •ì˜
X = "ë…ë¦½ ë³€ìˆ˜ (Independent Variable)" # # ì£¼ì„: ëª¨ë¸ì˜ ì…ë ¥ê°’ (ì›ì¸)
Y = "ì¢…ì† ë³€ìˆ˜ (Dependent Variable)"   # # ì£¼ì„: ì˜ˆì¸¡í•˜ë ¤ëŠ” ëª©í‘œ ë³€ìˆ˜ (ê²°ê³¼)

# í•™ìŠµ ìœ í˜• êµ¬ë¶„
LEARNING_TYPE_SUPERVISED = "Xì™€ Y(ì •ë‹µ)ë¥¼ ëª¨ë‘ ì‚¬ìš©" # # ì£¼ì„: ì§€ë„ í•™ìŠµ (Supervised Learning)
LEARNING_TYPE_UNSUPERVISED = "Xë§Œ ì‚¬ìš©í•˜ì—¬ íŒ¨í„´ ë°œê²¬" # # ì£¼ì„: ë¹„ì§€ë„ í•™ìŠµ (Unsupervised Learning)

# ==============================================================================
# 3ì£¼ì°¨: í…ì„œ, ë°ì´í„° ì „ì²˜ë¦¬ ë° ML ì•Œê³ ë¦¬ì¦˜ (K-NN, SVM)
# ==============================================================================

# í…ì„œ (Tensor)
DATA_STRUCTURE = "3ì°¨ì› ì´ìƒì˜ ë°°ì—´" # # ì£¼ì„: ë”¥ëŸ¬ë‹ì—ì„œ ë°ì´í„°ëŠ” í…ì„œ í˜•íƒœë¡œ í‘œí˜„ë¨

# ì›-í•« ì¸ì½”ë”© (One-Hot Encoding)
def one_hot_encode(category_list):
    vector = [0] * len(category_list)
    # # ì£¼ì„: ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ì‹ ê²½ë§ì´ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜ (í•´ë‹¹ ìœ„ì¹˜ì—ë§Œ 1 ë¶€ì—¬)
    vector[category_list.index(category)] = 1
    return vector

# SVM (Support Vector Machine)ì˜ ëª©í‘œ
SVM_GOAL = "Maximize Margin" # # ì£¼ì„: ì´ˆí‰ë©´ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„°(ì„œí¬íŠ¸ ë²¡í„°) ì‚¬ì´ì˜ ë§ˆì§„ì„ ìµœëŒ€í™”

# ==============================================================================
# 4ì£¼ì°¨: ë¨¸ì‹ ëŸ¬ë‹ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ (Decision Tree, Regression)
# ==============================================================================

# ê²°ì • íŠ¸ë¦¬ (Decision Tree) ë…¸ë“œ ë¶„í•  ê¸°ì¤€
def calculate_information_gain(parent_impurity, children_impurity_avg):
    # # ì£¼ì„: ë…¸ë“œ ë¶„í•  ì‹œ, ë¶ˆìˆœë„(Impurity) ê°ì†ŒëŸ‰ì¸ ì •ë³´ ì´ë“ì´ ìµœëŒ€ê°€ ë˜ë„ë¡ ë¶„í• 
    return parent_impurity - children_impurity_avg 

# ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logistic Regression) ëª¨ë¸
# # ì£¼ì„: ì„ í˜• íšŒê·€ ê²°ê³¼ë¥¼ Sigmoid í•¨ìˆ˜ì— ì ìš©í•˜ì—¬ 0~1 ì‚¬ì´ì˜ í™•ë¥ ë¡œ ë³€í™˜ (ë¶„ë¥˜ ëª¨ë¸)
LOGISTIC_MODEL = "P(Y=1) = 1 / (1 + exp(-(W*x + b)))" 

# ì„ í˜• íšŒê·€ (Linear Regression) ëª¨ë¸
LINEAR_MODEL = "y = W * x + b" # # ì£¼ì„: ë…ë¦½ë³€ìˆ˜(x)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¢…ì†ë³€ìˆ˜(y)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ìµœì ì˜ ì§ì„ 

# ==============================================================================
# 5ì£¼ì°¨: ë”¥ëŸ¬ë‹ ê¸°ë³¸ ìš”ì†Œì™€ ìµœì í™” ë° ë¹„ì§€ë„ í•™ìŠµ (PCA)
# ==============================================================================

# ê²½ì‚¬ í•˜ê°•ë²• (Gradient Descent) - ê°€ì¤‘ì¹˜ ê°±ì‹  ê³µì‹
def update_weights_SGD(W_old, LR, gradient):
    # # ì£¼ì„: ì†ì‹¤ í•¨ìˆ˜ ê¸°ìš¸ê¸°(gradient)ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ í•™ìŠµë¥ (LR)ë§Œí¼ ê°€ì¤‘ì¹˜ ê°±ì‹ 
    W_new = W_old - LR * gradient
    return W_new

# NAG (Nesterov Accelerated Gradient) ì˜µí‹°ë§ˆì´ì € ì›ë¦¬
# # ì£¼ì„: ëª¨ë©˜í…€ì´ ì ìš©ëœ 'ë¯¸ë¦¬ ì´ë™í•œ ì§€ì 'ì—ì„œ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•˜ì—¬ ëª¨ë©˜í…€ì˜ ë‹¨ì (ê³¼ë„í•œ ì´ë™) ê°œì„ 
NAG_PRINCIPLE = "Update_at(W + Momentum_direction) using new_gradient"

# PCA (Principal Component Analysis)
# # ì£¼ì„: ë°ì´í„°ì˜ ì°¨ì› ì¶•ì†Œ ê¸°ë²•. ë¶„ì‚°ì´ ê°€ì¥ í° ë°©í–¥(ì£¼ì„±ë¶„)ì„ ì°¾ì•„ ë°ì´í„°ë¥¼ ì••ì¶•
PCA_GOAL = "Find Principal Components (Max Variance) for Dimensionality Reduction"

# ==============================================================================
# 6ì£¼ì°¨: í•©ì„±ê³± ì‹ ê²½ë§ (CNN)ì˜ êµ¬ì„± ìš”ì†Œ
# ==============================================================================

# í•©ì„±ê³± ì¸µ (Convolutional Layer)ì˜ ì¶œë ¥ í¬ê¸° ê³„ì‚° ê³µì‹
def calculate_output_size(H_in, F, P, S):
    # # ì£¼ì„: í•„í„°(F) ì ìš© í›„ íŠ¹ì§• ë§µì˜ í¬ê¸° ê³„ì‚° (H_in: ì…ë ¥ í¬ê¸°, P: íŒ¨ë”©, S: ìŠ¤íŠ¸ë¼ì´ë“œ)
    H_out = (H_in - F + 2 * P) // S + 1 
    return H_out

# í’€ë§ ì¸µ (Pooling Layer)ì˜ ëª©ì 
POOLING_GOAL = "Down-sampling" # # ì£¼ì„: íŠ¹ì§• ë§µì˜ ì°¨ì›ì„ ì¤„ì—¬ ê³„ì‚°ëŸ‰ ê°ì†Œ ë° ëª¨ë¸ì˜ ê°•ì¸ì„± í™•ë³´

# GCN (Graph Convolutional Network)ì˜ ì…ë ¥ ë°ì´í„° ë³€í™˜
# # ì£¼ì„: ê·¸ë˜í”„ êµ¬ì¡° ë°ì´í„°ë¥¼ ì‹ ê²½ë§ì´ ì²˜ë¦¬í•˜ë„ë¡ ì¸ì ‘ í–‰ë ¬(Adjacency Matrix)ë¡œ ë³€í™˜
GCN_INPUT_TRANSFORM = "Graph -> Adjacency Matrix (ì¸ì ‘ í–‰ë ¬)"

# ==============================================================================
# 7ì£¼ì°¨: LeNet-5 ë° CNN ì‹¬í™” (ResNet)
# ==============================================================================

# LeNet-5 êµ¬ì¡°ì˜ ê¸°ë³¸ ì›ë¦¬
# # ì£¼ì„: CNNì˜ ì´ˆì„ì´ ëœ êµ¬ì¡°. í•©ì„±ê³±(C)ê³¼ ë‹¤ìš´ ìƒ˜í”Œë§/í’€ë§(S)ì„ ë°˜ë³µí•˜ì—¬ ê³„ì¸µì ìœ¼ë¡œ íŠ¹ì§• ì¶”ì¶œ
LE_NET_5_STRUCTURE = "C -> S -> C -> S -> F(ì™„ì „ì—°ê²°)"

# ResNet (Residual Network) - ì”ì°¨ í•™ìŠµ ë¸”ë¡ êµ¬ì¡°
def residual_block(x):
    F_x = layers(x)
    # # ì£¼ì„: ìˆì»·(Skip Connection)ì„ í†µí•´ ì…ë ¥(x)ì„ ì”ì°¨(F_x)ì— ë”í•´ ì”ì°¨ í•™ìŠµ ìˆ˜í–‰
    H_x = F_x + x 
    return H_x
