{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluemoon-17/KEVIN/blob/main/2Grade/1Simester/DeepLearning%20Programming/ch02_colab_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3qKPCqkIM8l"
      },
      "source": [
        "# 2장. 딥러닝 핵심 미리보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aGnqS4iIM8p"
      },
      "source": [
        "## 나의 첫 딥러닝: '10장 폐암 수술 환자의 생존율 예측' 코드 미리보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbVYiBTEIM8q"
      },
      "source": [
        "### 1. 환경 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L4eubqQbIM8r"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential  # 텐서플로의 케라스 API에서 필요한 함수들을 불러옵니다.\n",
        "from tensorflow.keras.layers import Dense       # 데이터를 다루는 데 필요한 라이브러리를 불러옵니다.\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5TWyXHBIM8s"
      },
      "source": [
        "### 2. 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xq0LZLNrIM8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24d6c50-15d2-48b2-e08c-1ca5d4c77514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 36 (delta 9), reused 26 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (36/36), 483.12 KiB | 6.53 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/taehojo/data.git   # 깃허브에 준비된 데이터를 가져옵니다.\n",
        "\n",
        "Data_set = np.loadtxt(\"./data/ThoraricSurgery3.csv\", delimiter=\",\")  # 수술 환자 데이터를 불러옵니다.\n",
        "X = Data_set[:,0:16]                                                 # 환자의 진찰 기록을 X로 지정합니다.\n",
        "y = Data_set[:,16]                                                   # 수술 후 사망/생존 여부를 y로 지정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X_6wZ6ZIM8t"
      },
      "source": [
        "### 3. 구조 결정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BHUiEfJmIM8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60bbcd2-38b6-4d50-9288-1e0b15d06870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()                                                  # 딥러닝 모델의 구조를 결정합니다.\n",
        "model.add(Dense(30, input_dim=16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVbNJR7PIM8u"
      },
      "source": [
        "### 4. 모델 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "byeiH13hIM8u",
        "outputId": "5d76a805-f41c-40cf-d21c-d39653674e7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8304 - loss: 1.2291\n",
            "Epoch 2/5\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8358 - loss: 0.8454\n",
            "Epoch 3/5\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8109 - loss: 0.7647\n",
            "Epoch 4/5\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8151 - loss: 0.5009\n",
            "Epoch 5/5\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8495 - loss: 0.4441\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # 딥러닝 모델을 실행합니다.\n",
        "history=model.fit(X, y, epochs=5, batch_size=16)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}