### ✅ 머신러닝 개념 정리 (문서 전체 기반)

| 개념                     | 설명                                                                                      |
|--------------------------|-------------------------------------------------------------------------------------------|
| 머신러닝 정의             | 명시적인 규칙 없이 컴퓨터가 데이터를 통해 학습하도록 만드는 기술<br> - 작업 T<br> - 성능 측정 P<br> - 경험 E |
| 머신러닝 사용 이유        | - 복잡한 규칙을 사람이 직접 정의하기 어려움<br> - 자동으로 변화에 적응<br> - 대규모 데이터에서 패턴 발견 가능 |
| 머신러닝 종류             | - 지도 학습<br>- 비지도 학습<br>- 준지도 학습<br>- 자기 지도 학습<br>- 강화 학습                        |
| 지도 학습                | 레이블이 있는 데이터로 학습<br>예: 분류(스팸 필터), 회귀(가격 예측)                                |
| 비지도 학습              | 레이블 없는 데이터에서 패턴을 스스로 학습<br>예: 군집, 차원 축소, 이상치 탐지                         |
| 강화 학습                | 보상 기반으로 환경과 상호작용하며 최적 정책 학습<br>에이전트-환경-보상-정책 반복                       |
| 배치 학습                | 모든 데이터를 한꺼번에 학습 (오프라인)                                                      |
| 온라인 학습              | 데이터를 순차적으로 받아 점진적으로 학습 (실시간)                                           |
| 외부 메모리 학습         | 너무 큰 데이터를 작은 단위로 나눠 메모리 밖에서 학습 (out-of-core learning)                    |
| 사례 기반 학습           | 샘플 기억 + 유사도 비교로 예측 (예: k-NN)                                                  |
| 모델 기반 학습           | 훈련 데이터로 수학적 모델 생성 (예: 선형 회귀, 결정 트리, SVM 등)                              |
| 학습률 (learning rate)   | 온라인 학습에서 새 데이터에 얼마나 빠르게 반응할지 조절하는 파라미터                             |
| 훈련 세트                | 모델을 학습시키기 위한 입력 데이터                                                         |
| 테스트 세트              | 학습에 사용하지 않고, 성능 평가를 위한 데이터                                              |
| 일반화 오차              | 모델이 **새로운 데이터**에 대해 얼마나 잘 예측하는지 측정한 오차                              |
| 과대적합 (Overfitting)   | 훈련 데이터에 너무 맞춰져 일반화 성능이 떨어짐                                            |
| 과소적합 (Underfitting)  | 모델이 너무 단순해 데이터 패턴을 잘 학습하지 못함                                          |
| 하이퍼파라미터 튜닝      | 모델의 성능 향상을 위한 설정 조정<br>(예: GridSearchCV, RandomSearchCV)                         |
| 성능 측정 지표           | 분류: 정확도, 정밀도, 재현율, F1 점수, ROC AUC<br>회귀: MAE, MSE, RMSE 등                        |
| 다중 분류                | 다수의 클래스를 분류 (OvR, OvO 전략)                                                       |
| MNIST                    | 28x28 손글씨 숫자 이미지 데이터셋 (0~9)<br>훈련: 60,000 / 테스트: 10,000                       |
| 머신러닝 전체 프로젝트 과정 | ① 문제 정의 → ② 데이터 수집 → ③ 탐색 & 전처리 → ④ 특성 엔지니어링 → ⑤ 모델 선택 & 훈련 → ⑥ 평가 & 튜닝 → ⑦ 배포 & 모니터링 |

### ✅ 머신러닝 주요 개념 + 메서드/속성 정리

| 개념/구분              | 메서드 / 속성 / 함수                    | 설명                                                                 |
|------------------------|------------------------------------------|----------------------------------------------------------------------|
| 데이터프레임 탐색       | `head()`, `info()`, `describe()`         | 데이터의 형태와 요약 통계 확인                                        |
| 시각화                 | `hist()`, `scatter_matrix()`, `imshow()`| 히스토그램, 산점도 행렬, 이미지 시각화                               |
| 상관관계               | `corr()`                                 | 피어슨 상관계수 계산                                                  |
| 결측값 처리            | `dropna()`, `fillna()`, `SimpleImputer` | 결측값 제거 또는 평균/중간값 대체                                     |
| 특성 인코딩            | `OrdinalEncoder`, `OneHotEncoder`        | 범주형 데이터 숫자 또는 원-핫 인코딩                                  |
| 범주형 확인            | `categories_`                            | 인코더가 인식한 범주 목록 확인                                        |
| 변환기 구성            | `FunctionTransformer`, `Pipeline`        | 사용자 정의 변환 또는 전처리 조합 구성                                |
| 데이터 분할            | `train_test_split()`, `StratifiedShuffleSplit` | 훈련/테스트 셋 분할 (계층적 분할 포함)                               |
| 모델 학습/예측         | `fit()`, `predict()`, `fit_transform()`  | 모델 학습, 예측, 변환기 동시 실행                                      |
| 회귀 성능 평가         | `mean_squared_error()`, `mean_absolute_error()` | RMSE, MAE 계산용                                                      |
| 분류 성능 평가         | `accuracy_score`, `precision_score`, `recall_score`, `f1_score` | 정확도, 정밀도, 재현율, F1 점수 측정                                 |
| 분류 시 시각화         | `confusion_matrix()`, `ConfusionMatrixDisplay` | 오차 행렬 계산 및 시각화                                              |
| 점수 확인              | `decision_function()`                    | 분류기의 결정 점수 반환                                                |
| 임곗값 조정            | `precision_recall_curve()`               | 정밀도-재현율 변화 시각화용 데이터 생성                               |
| ROC 평가               | `roc_curve()`, `roc_auc_score()`         | ROC 곡선과 AUC 점수 계산                                               |
| 교차 검증              | `cross_val_score()`, `cross_val_predict()`| 교차 검증 점수, 예측값 계산                                            |
| 하이퍼파라미터 튜닝    | `GridSearchCV`, `RandomizedSearchCV`     | 모델의 하이퍼파라미터 탐색                                            |
| 다중 분류 지원         | `OneVsOneClassifier`, `OneVsRestClassifier`| OvO, OvR 방식 수동 지정 가능                                           |
| 다중 레이블 분류       | `ClassifierChain`, `f1_score(average="weighted")` | 다중 타깃 분류기 훈련 및 평가                                         |
| 특성 확장              | `PolynomialFeatures`                     | 다항 특성 생성                                                        |
| 클러스터링 기반 변환기 | `KMeans`, `rbf_kernel()`                 | 클러스터 중심과의 유사도 기반 특성 생성                              |
| SVM                   | `SVC`, `LinearSVC`, `SVR`, `LinearSVR`    | 분류/회귀용 SVM 모델                                                  |

### ✅ 머신러닝 주요 메서드 / 속성 / 함수 정리 (개념별)

| 이름                        | 설명                                                                 |
|-----------------------------|----------------------------------------------------------------------|
| `head()`                    | 데이터프레임의 **상위 5개 행**을 확인할 때 사용. 데이터가 어떤 형식인지 빠르게 파악 가능 |
| `info()`                    | 열 이름, 데이터 타입, 결측값 여부 등 **데이터 구조 요약 정보** 제공                    |
| `describe()`                | 수치형 데이터의 **기본 통계량 (평균, 표준편차, 사분위수 등)** 요약                       |
| `hist()`                    | 모든 수치형 열의 **히스토그램** 시각화. 분포 확인에 유용                                    |
| `scatter_matrix()`          | 여러 수치형 변수 간의 관계를 **산점도 행렬**로 시각화                                     |
| `imshow()`                  | 이미지 형태의 2D 데이터를 시각화. MNIST 숫자 이미지 등 표현에 사용                          |
| `corr()`                    | 데이터프레임의 수치형 열들 간 **상관계수(Pearson's r)**를 계산                           |
| `dropna()`                  | 결측값이 포함된 행/열을 삭제                                                                  |
| `fillna()`                  | 결측값을 지정한 값(예: 평균, 중간값)으로 채움                                               |
| `SimpleImputer`             | 결측값을 **자동으로 대체하는 전처리기**. 전략 지정 가능 (평균, 중간값 등)                    |
| `OrdinalEncoder`            | 범주형 값을 **정수 인덱스로 인코딩** (순서가 있는 카테고리일 때 적합)                       |
| `OneHotEncoder`             | 범주형 값을 **0과 1로 구성된 벡터(원-핫 인코딩)**로 변환                                   |
| `categories_`               | 인코딩된 범주 정보 저장. 모델이 어떤 값을 인식했는지 확인 가능                             |
| `FunctionTransformer`       | 사용자 정의 **변환 함수**를 전처리 파이프라인에 포함할 때 사용                             |
| `Pipeline`                  | 여러 전처리 및 모델 단계를 **하나의 객체로 연결**하여 처리                                   |
| `train_test_split()`        | 훈련/테스트 데이터를 **무작위로 분할**                                                       |
| `StratifiedShuffleSplit`    | 레이블의 분포를 유지하면서 데이터셋을 **계층적 무작위 분할**                                 |
| `fit()`                     | 모델이나 변환기를 **훈련 데이터에 맞춤 (학습)**                                              |
| `predict()`                 | 학습된 모델을 이용해 **새로운 데이터 예측**                                                  |
| `fit_transform()`           | 학습 + 변환을 한 번에 수행 (주로 전처리기에 사용됨)                                         |
| `mean_squared_error()`      | 예측값과 실제값 사이의 **제곱 오차 평균 (MSE)**를 계산. 회귀 성능 평가용                    |
| `mean_absolute_error()`     | 예측값과 실제값 사이의 **절대 오차 평균 (MAE)** 계산                                         |
| `accuracy_score()`          | 분류 모델의 **정확도 (전체 중 맞춘 비율)** 계산                                              |
| `precision_score()`         | 예측한 것 중 **정답(양성)이었던 비율** 계산                                                 |
| `recall_score()`            | 실제 양성 중 **정확히 예측한 비율 (재현율)** 계산                                           |
| `f1_score()`                | 정밀도와 재현율의 **조화 평균**. 두 지표 간 균형 판단에 좋음                                |
| `confusion_matrix()`        | 예측 결과와 실제 결과 간의 **오차 행렬** 생성                                               |
| `ConfusionMatrixDisplay`    | 오차 행렬을 **시각화하는 유틸리티 클래스**                                                  |
| `decision_function()`       | 각 샘플에 대해 **결정 점수**(임곗값 이전 단계)를 반환                                        |
| `precision_recall_curve()`  | 다양한 **임곗값에 따른 정밀도/재현율 값**을 계산                                           |
| `roc_curve()`               | **FPR(거짓 양성 비율)**과 **TPR(재현율)**에 대한 ROC 커브용 좌표 계산                      |
| `roc_auc_score()`           | **ROC 곡선 아래 면적(AUC)**. 1에 가까울수록 좋은 모델                                       |
| `cross_val_score()`         | k-폴드 교차 검증을 통해 **정확도/점수 평균을 계산**                                        |
| `cross_val_predict()`       | k-폴드 교차 검증에서 **예측 결과 배열을 반환** (점수 대신 예측 결과 필요할 때 사용)         |
| `GridSearchCV`              | 여러 하이퍼파라미터 조합을 **그리드 탐색**하여 최적 조합을 찾음                            |
| `RandomizedSearchCV`        | 하이퍼파라미터 조합을 **무작위로 일부만 선택**해 빠르게 탐색                               |
| `OneVsOneClassifier`        | 다중 분류 문제에서 **클래스 쌍마다 이진 분류기 생성**                                       |
| `OneVsRestClassifier`       | 각 클래스를 나머지 전체와 구분하는 **이진 분류기 생성 (OvR)**                             |
| `ClassifierChain`           | 다중 레이블 문제에서 **이전 모델 예측 결과를 다음 모델 입력에 연결**                        |
| `PolynomialFeatures`        | 입력 특성을 다항식 조합으로 **확장**                                                        |
| `KMeans`                    | 비지도 학습 기반 **클러스터 중심 추정 알고리즘**                                            |
| `rbf_kernel()`              | 두 벡터 사이의 **가우시안 유사도** 계산                                                     |
| `SVC`, `LinearSVC`          | SVM 기반 분류기. 선형 또는 비선형 경계 가능                                                  |
| `SVR`, `LinearSVR`          | SVM 기반 회귀 모델 (분류와 달리 마진 내에서 예측)                                           |
