# âœ… ë¨¸ì‹ ëŸ¬ë‹ ì¤‘ê°„ê³ ì‚¬ ì •ë¦¬ (ì˜ˆì œ ì½”ë“œ í¬í•¨)
## 1ï¸âƒ£ ë¨¸ì‹ ëŸ¬ë‹ì´ë€?
ì •ì˜: ë°ì´í„°ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜

ì˜ˆì‹œ: ìŠ¤íŒ¸ í•„í„°, ììœ¨ì£¼í–‰, ì´ë¯¸ì§€ ë¶„ë¥˜


# âœ… ë¨¸ì‹ ëŸ¬ë‹ì„ ì‚¬ìš©í•˜ëŠ” ì´ìœ  ìš”ì•½
## ì „í†µì  í”„ë¡œê·¸ë˜ë° ë°©ì‹ì˜ í•œê³„ ê·¹ë³µ

ê·œì¹™ ê¸°ë°˜ í”„ë¡œê·¸ë˜ë°ì€ ê·œì¹™ì´ ë³µì¡í•´ì§€ê³  ê¸¸ì–´ì§ˆìˆ˜ë¡ ìœ ì§€ë³´ìˆ˜ê°€ ì–´ë µê³ , ì •í™•ë„ë„ ë‚®ì•„ì§€ëŠ” ë¬¸ì œê°€ ìˆìŒ.
â†’ ë¨¸ì‹ ëŸ¬ë‹ì€ ë³µì¡í•œ ê·œì¹™ì„ ì‚¬ëŒì´ ì§ì ‘ ì •ì˜í•˜ì§€ ì•Šê³ , ë°ì´í„°ì—ì„œ ìë™ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ë” ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ ìˆ˜ ìˆìŒ.

## ìë™ìœ¼ë¡œ ë³€í™”ì— ì ì‘ ê°€ëŠ¥

ë¨¸ì‹ ëŸ¬ë‹ ì‹œìŠ¤í…œì€ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ë³€í™”í•˜ëŠ” í™˜ê²½ì— ìë™ìœ¼ë¡œ ì ì‘í•  ìˆ˜ ìˆìŒ.
ì˜ˆ: ì‚¬ìš©ìê°€ ìŠ¤íŒ¸ìœ¼ë¡œ ì§€ì •í•œ ë‹¨ì–´(ì˜ˆ: "For U")ë¥¼ ìë™ìœ¼ë¡œ í•™ìŠµí•´ì„œ ê·¸ ë‹¨ì–´ê°€ í¬í•¨ëœ ë©”ì¼ì„ ìŠ¤íŒ¸ìœ¼ë¡œ ë¶„ë¥˜í•¨.

## ëŒ€ëŸ‰ì˜ ë°ì´í„°ì—ì„œ ìœ ìš©í•œ íŒ¨í„´ ë°œê²¬ ê°€ëŠ¥

ë°ì´í„° ë§ˆì´ë‹ ê¸°ëŠ¥: ë¨¸ì‹ ëŸ¬ë‹ì€ ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ëŒì´ ì°¾ê¸° ì–´ë ¤ìš´ ìˆ¨ê²¨ì§„ íŒ¨í„´ì„ ì°¾ì•„ëƒ„.

## ë³µì¡í•˜ê±°ë‚˜ ê¸°ì¡´ ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œìœ¼ë¡œëŠ” í•´ê²°ì´ ì–´ë ¤ìš´ ë¬¸ì œ ì²˜ë¦¬ ê°€ëŠ¥

ì˜ˆì¸¡, ë¶„ë¥˜, ì´ìƒì¹˜ íƒì§€ ë“± ë‹¤ì–‘í•œ ë³µì¡í•œ ë¬¸ì œë¥¼ ê¸°ì¡´ ë°©ì‹ë³´ë‹¤ ë” ë†’ì€ ì„±ëŠ¥ìœ¼ë¡œ í•´ê²°.

## ìœ ë™ì ì¸ í™˜ê²½ì—ì„œë„ ì ì‘ë ¥ ë³´ì¥

ëª¨ë¸ì€ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ í†µí•´ ì‰½ê²Œ ì¬í›ˆë ¨ì´ ê°€ëŠ¥í•˜ì—¬ í•­ìƒ ìµœì‹  ìƒíƒœ ìœ ì§€ ê°€ëŠ¥.

## ì •í™•ë„ í–¥ìƒ

ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì€ ì¼ë°˜ì ìœ¼ë¡œ ìˆ˜ë™ ê·œì¹™ ê¸°ë°˜ë³´ë‹¤ ì •í™•ë„ê°€ ë†’ìŒ.
ì˜ˆ: ìŠ¤íŒ¸ í•„í„°, ì´ë¯¸ì§€ ë¶„ë¥˜, ìŒì„± ì¸ì‹ ë“±

# ë¨¸ì‹ ëŸ¬ë‹ì˜ ì¢…ë¥˜

| ì¢…ë¥˜            | ì„¤ëª…                                         | ì˜ˆì‹œ                                                       |
|-----------------|----------------------------------------------|------------------------------------------------------------|
| ì§€ë„ í•™ìŠµ       | ì…ë ¥ê³¼ ì •ë‹µ(ë ˆì´ë¸”)ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ           | ë¶„ë¥˜(ìŠ¤íŒ¸ í•„í„°, ì†ê¸€ì”¨ ì¸ì‹), íšŒê·€(ì£¼íƒ ê°€ê²© ì˜ˆì¸¡ ë“±)       |
| ë¹„ì§€ë„ í•™ìŠµ     | ë ˆì´ë¸” ì—†ì´ ë°ì´í„° êµ¬ì¡°ë‚˜ íŒ¨í„´ì„ í•™ìŠµ         | êµ°ì§‘(ê³ ê° ì„¸ë¶„í™”), ì°¨ì› ì¶•ì†Œ(PCA), ì´ìƒì¹˜ íƒì§€, ì—°ê´€ ê·œì¹™ í•™ìŠµ |
| ê°•í™” í•™ìŠµ       | ë³´ìƒ/ë²Œì ì„ í†µí•´ ìµœì ì˜ í–‰ë™ ì „ëµ í•™ìŠµ        | ê²Œì„ AI, ë¡œë´‡ ì œì–´, ììœ¨ì£¼í–‰                               |
| ì¤€ì§€ë„ í•™ìŠµ     | ì¼ë¶€ë§Œ ë ˆì´ë¸”ëœ ë°ì´í„°ë¡œ í•™ìŠµ                 | ì†ŒëŸ‰ì˜ ë ˆì´ë¸” + ëŒ€ëŸ‰ì˜ ë¬´ë¼ë²¨ ì´ë¯¸ì§€ ë¶„ë¥˜ ë“±               |
| ìê¸° ì§€ë„ í•™ìŠµ  | ë°ì´í„°ë¡œë¶€í„° ìŠ¤ìŠ¤ë¡œ ë ˆì´ë¸” ìƒì„±í•´ í•™ìŠµ        | GPT, BERT, CLIP ë“± ì‚¬ì „í•™ìŠµ ì–¸ì–´/ë¹„ì „ ëª¨ë¸                 |
| ë°°ì¹˜ í•™ìŠµ       | ëª¨ë“  ë°ì´í„°ë¥¼ í•œêº¼ë²ˆì— í•™ìŠµ (ì˜¤í”„ë¼ì¸)         | ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ í™œìš©í•œ ëª¨ë¸ í•™ìŠµ                         |
| ì˜¨ë¼ì¸ í•™ìŠµ     | ë°ì´í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë°›ì•„ ì ì§„ì ìœ¼ë¡œ í•™ìŠµ       | ì‹¤ì‹œê°„ ì¶”ì²œ ì‹œìŠ¤í…œ, ê¸ˆìœµ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ                   |
| ì‚¬ë¡€ ê¸°ë°˜ í•™ìŠµ  | ê³¼ê±° ì‚¬ë¡€ì™€ì˜ ìœ ì‚¬ë„ ê¸°ë°˜ ì˜ˆì¸¡                | K-ìµœê·¼ì ‘ ì´ì›ƒ(K-NN), ë©”ëª¨ë¦¬ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜                   |
| ëª¨ë¸ ê¸°ë°˜ í•™ìŠµ  | ì¼ë°˜í™”ëœ ìˆ˜í•™ì  ëª¨ë¸ì„ ë§Œë“¤ì–´ ì˜ˆì¸¡            | ì„ í˜• íšŒê·€, ê²°ì • íŠ¸ë¦¬, SVM, ì‹ ê²½ë§ ë“±                       |

# ğŸ“Œ ì§€ë„ í•™ìŠµ(Supervised Learning)
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

## ë°ì´í„° ë¡œë“œ
digits = load_digits()
X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)

## ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

## ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"ì •í™•ë„: {accuracy:.2f}")

î·›î·œî·™î·š

# ğŸ“Œ ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) - K-Means êµ°ì§‘í™”
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

## ë°ì´í„° ìƒì„±
X, _ = make_blobs(n_samples=300, centers=3, cluster_std=0.60, random_state=42)

## K-Means ëª¨ë¸ í•™ìŠµ
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X)
y_kmeans = kmeans.predict(X)

## ë°ì´í„° ì‹œê°í™”
plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, cmap='viridis')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', marker='X')
plt.show()

î·›î·œî·™î·š

# ğŸ“Œ ê°•í™” í•™ìŠµ(Reinforcement Learning) - Q-Learning ì˜ˆì œ
import numpy as np

## Q í…Œì´ë¸” ì´ˆê¸°í™”
Q = np.zeros((5, 5))

## íŒŒë¼ë¯¸í„° ì„¤ì •
alpha = 0.1  # í•™ìŠµë¥ 
gamma = 0.9  # í• ì¸ìœ¨
epsilon = 0.1  # íƒìƒ‰ í™•ë¥ 

## í•™ìŠµ ê³¼ì • (ë‹¨ìˆœ ì˜ˆì œ)
for episode in range(100):
    state = np.random.randint(5)
    for step in range(10):
        if np.random.rand() < epsilon:
            action = np.random.randint(5)  # ëœë¤ í–‰ë™ ì„ íƒ
        else:
            action = np.argmax(Q[state])  # ìµœì  í–‰ë™ ì„ íƒ
        reward = np.random.randint(-1, 2)  # ë³´ìƒ ì„¤ì •
        Q[state, action] = Q[state, action] + alpha * (reward + gamma * np.max(Q[action]) - Q[state, action])

print("í•™ìŠµëœ Q í…Œì´ë¸”:")
print(Q)

î·›î·œî·™î·š

ì´ë ‡ê²Œ ì •ë¦¬í•˜ë©´ ì½”ë“œ ë¶€ë¶„ë§Œ ë°°ê²½ìƒ‰ì´ ë‹¤ë¥´ê²Œ í‘œì‹œë˜ì–´ ê°€ë…ì„±ì´ ì¢‹ì„ ê±°ì˜ˆìš”. í•„ìš”í•œ ë¶€ë¶„ì´ ë” ìˆìœ¼ë©´ ì•Œë ¤ì£¼ì„¸ìš”! ğŸ˜Š

# âœ… ë¨¸ì‹ ëŸ¬ë‹ì˜ ì£¼ìš” ë„ì „ ê³¼ì œ

| ë„ì „ ê³¼ì œ               | ì„¤ëª…                                                                                   |
|------------------------|----------------------------------------------------------------------------------------|
| ë¯¿ê¸° í˜ë“  ë°ì´í„°ì˜ íš¨ê³¼ | ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤ ì–‘ì§ˆì˜ ë°ì´í„°ê°€ ë” ì¤‘ìš”í•¨. ì¶©ë¶„í•œ ë°ì´í„°ë§Œ ìˆë‹¤ë©´ ë‹¨ìˆœí•œ ì•Œê³ ë¦¬ì¦˜ë„ ì„±ëŠ¥ì´ ì¢‹ì„ ìˆ˜ ìˆìŒ |
| ë°ì´í„° ë¶€ì¡±            | ë¨¸ì‹ ëŸ¬ë‹ì€ ë§ì€ ì–‘ì˜ í›ˆë ¨ ë°ì´í„°ê°€ í•„ìš”. íŠ¹íˆ ì´ë¯¸ì§€/ìŒì„±ì€ ìˆ˜ì²œ~ìˆ˜ë°±ë§Œ ê°œ í•„ìš”í•¨                |
| ëŒ€í‘œì„± ë¶€ì¡±            | í›ˆë ¨ ë°ì´í„°ê°€ ì‹¤ì œ ë¬¸ì œë¥¼ ì˜ ëŒ€í‘œí•˜ì§€ ëª»í•˜ë©´ ì¼ë°˜í™”ê°€ ì–´ë µê³  ì„±ëŠ¥ ì €í•˜                         |
| ë‚®ì€ ë°ì´í„° í’ˆì§ˆ       | ì´ìƒì¹˜, ì˜¤ë¥˜, ëˆ„ë½ëœ ê°’ ë“± ë°ì´í„° ì •ì œê°€ ë°˜ë“œì‹œ í•„ìš”                                      |
| ê´€ë ¨ ì—†ëŠ” íŠ¹ì„±         | ë¶ˆí•„ìš”í•˜ê±°ë‚˜ ìƒê´€ì—†ëŠ” íŠ¹ì„±ì´ ë§ìœ¼ë©´ ëª¨ë¸ í•™ìŠµì„ ë°©í•´í•¨ â†’ íŠ¹ì„± ì„ íƒ/ì¶”ì¶œ í•„ìš”                  |
| ê³¼ëŒ€ì í•© (Overfitting) | ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ë„ˆë¬´ ë§ì¶°ì ¸ ìƒˆ ë°ì´í„°ì—ì„œ ì„±ëŠ¥ì´ ë‚˜ì¨                                 |
| ê³¼ì†Œì í•© (Underfitting)| ëª¨ë¸ì´ ë„ˆë¬´ ë‹¨ìˆœí•˜ê±°ë‚˜ í•™ìŠµì´ ë¶€ì¡±í•˜ì—¬ ë°ì´í„°ì˜ êµ¬ì¡°ë¥¼ ì˜ í•™ìŠµí•˜ì§€ ëª»í•¨                     |
| ì¡ìŒ ë§ì€ ë°ì´í„°       | ë…¸ì´ì¦ˆê°€ ë§ì€ ë°ì´í„°ëŠ” ëª¨ë¸ì´ ì—‰ëš±í•œ íŒ¨í„´ì„ í•™ìŠµí•˜ê²Œ ë§Œë“¦                                   |
| í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ë¬¸ì œ | í•™ìŠµë¥ , ê·œì œ ê³„ìˆ˜ ë“±ì˜ ì˜ëª»ëœ ì„¤ì •ì€ ì„±ëŠ¥ ì €í•˜ë¡œ ì´ì–´ì§                                  |
| ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì–´ë ¤ì›€   | íŠ¹íˆ ì˜¨ë¼ì¸ í•™ìŠµì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì„±ëŠ¥ ê°ì‹œ ë° ì¡°ì¹˜ê°€ í•„ìš”                                    |
| ëª¨ë¸ ë¶€íŒ¨ (Model Rot)  | ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ë°ì´í„° ë¶„í¬ê°€ ë°”ë€Œë©´ ê¸°ì¡´ ëª¨ë¸ì´ ì ì  ì„±ëŠ¥ì´ ë‚˜ë¹ ì§ â†’ ì¬í•™ìŠµ í•„ìš”              |

# âœ… ë¨¸ì‹ ëŸ¬ë‹ì˜ í…ŒìŠ¤íŠ¸ì™€ ê²€ì¦ ì •ë¦¬

| í•­ëª©                    | ì„¤ëª…                                                                                  |
|-------------------------|-----------------------------------------------------------------------------------------|
| í›ˆë ¨ ì„¸íŠ¸ (Training Set) | ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë° ì‚¬ìš©í•˜ëŠ” ë°ì´í„°ì…‹                                                |
| í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ (Test Set)   | ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ë°ì´í„°ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ì…‹                                  |
| ê²€ì¦ ëª©ì                | ëª¨ë¸ì´ **ìƒˆë¡œìš´ ë°ì´í„°ì— ì–¼ë§ˆë‚˜ ì˜ ì¼ë°˜í™”ë˜ëŠ”ì§€** í™•ì¸í•˜ê¸° ìœ„í•´ ì‚¬ìš©                   |
| ì¼ë°˜í™” ì˜¤ì°¨             | í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ì¸¡ì •í•œ ì˜¤ë¥˜ ë¹„ìœ¨ â†’ ìƒˆë¡œìš´ ìƒ˜í”Œì— ëŒ€í•œ **ì˜ˆìƒ ì˜¤ì°¨**                      |
| ê³¼ëŒ€ì í•© í™•ì¸            | í›ˆë ¨ ì˜¤ì°¨ëŠ” ë‚®ì§€ë§Œ í…ŒìŠ¤íŠ¸ ì˜¤ì°¨ê°€ ë†’ë‹¤ë©´ ê³¼ëŒ€ì í•©ë¨                                      |
| í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ ë¹„ìœ¨    | ì¼ë°˜ì ìœ¼ë¡œ **80% í›ˆë ¨ / 20% í…ŒìŠ¤íŠ¸**, ë°ì´í„°ì…‹ í¬ê¸°ì— ë”°ë¼ ìœ ë™ì ìœ¼ë¡œ ì¡°ì ˆ ê°€ëŠ¥            |
| ë°ì´í„° ìŠ¤ëˆ„í•‘ ë°©ì§€       | í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ëŠ” **ì ˆëŒ€ í›ˆë ¨ì— ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜**                                     |
| êµì°¨ ê²€ì¦ (Cross Validation) | ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ ì„œ ë°˜ë³µì ìœ¼ë¡œ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì§„í–‰ â†’ **í‰ê·  ì„±ëŠ¥ì„ ì¶”ì •**               |
| k-í´ë“œ êµì°¨ ê²€ì¦        | ë°ì´í„°ë¥¼ kê°œì˜ í´ë“œë¡œ ë‚˜ëˆ , ê·¸ ì¤‘ í•˜ë‚˜ë¥¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ì‚¬ìš©í•˜ê³  ë‚˜ë¨¸ì§€ë¥¼ í›ˆë ¨ì— ì‚¬ìš© â†’ kë²ˆ ë°˜ë³µ |
| ê²€ì¦ ì„¸íŠ¸ (Validation Set) | í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë“±ì„ ìœ„í•œ ì¶”ê°€ì ì¸ í‰ê°€ìš© ë°ì´í„°ì…‹ (í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ë¡œ ë‚˜ëˆ„ê¸°ë„ í•¨)        |

# âœ… ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ìš”ì•½ (ì²˜ìŒë¶€í„° ëê¹Œì§€)

| ë‹¨ê³„               | ì„¤ëª…                                                                                   |
|--------------------|------------------------------------------------------------------------------------------|
| 1. ë¬¸ì œ ì •ì˜       | - ë¹„ì¦ˆë‹ˆìŠ¤ ëª©ì  ì´í•´<br>- ì˜ˆì¸¡í•´ì•¼ í•  ëŒ€ìƒ ì •ì˜<br>- íšŒê·€/ë¶„ë¥˜/êµ°ì§‘ ë“± ë¬¸ì œ ìœ í˜• íŒŒì•…   |
| 2. ë°ì´í„° ìˆ˜ì§‘     | - ë‹¤ì–‘í•œ ì†ŒìŠ¤ë¡œë¶€í„° ë°ì´í„° ìˆ˜ì§‘ (CSV, DB, API ë“±)<br>- ì‹ ë¢°ì„±ê³¼ í’ˆì§ˆ í™•ì¸               |
| 3. ë°ì´í„° íƒìƒ‰     | - ë°ì´í„° êµ¬ì¡° íŒŒì•… (`head()`, `info()`, `describe()` ë“±)<br>- ì‹œê°í™” ë° ìƒê´€ê´€ê³„ ë¶„ì„    |
| 4. ë°ì´í„° ì „ì²˜ë¦¬   | - ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ì´ìƒì¹˜ ì œê±°<br>- ë²”ì£¼í˜•/ìˆ˜ì¹˜í˜• ì¸ì½”ë”©<br>- ì •ê·œí™”/í‘œì¤€í™”                  |
| 5. íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ | - íŠ¹ì„± ì„ íƒ/ì¶”ì¶œ<br>- ìƒˆë¡œìš´ ìœ ìš©í•œ í”¼ì²˜ ìƒì„±<br>- ë„ë©”ì¸ ì§€ì‹ í™œìš©                     |
| 6. ë°ì´í„° ë¶„í•      | - í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„í• <br>- ê³„ì¸µì  ìƒ˜í”Œë§ ì‚¬ìš© ê¶Œì¥                               |
| 7. ëª¨ë¸ ì„ íƒ       | - ì ì ˆí•œ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ (ì„ í˜• íšŒê·€, ê²°ì • íŠ¸ë¦¬, ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë“±)<br>- ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ êµ¬ì¶• |
| 8. ëª¨ë¸ í›ˆë ¨       | - í›ˆë ¨ ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ í•™ìŠµ<br>- ë¹„ìš© í•¨ìˆ˜ ìµœì†Œí™”ë¡œ ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°               |
| 9. ëª¨ë¸ í‰ê°€       | - ê²€ì¦ ì„¸íŠ¸ ë˜ëŠ” êµì°¨ ê²€ì¦ìœ¼ë¡œ ì„±ëŠ¥ ì¸¡ì •<br>- RMSE, MAE, ì •í™•ë„, F1, ROC ë“± ì‚¬ìš©         |
|10. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹| - GridSearchCV ë˜ëŠ” RandomizedSearchCV ì‚¬ìš©<br>- ìµœì  ëª¨ë¸ íŒŒë¼ë¯¸í„° íƒìƒ‰             |
|11. ìµœì¢… í…ŒìŠ¤íŠ¸     | - í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ìµœì¢… ì„±ëŠ¥ í‰ê°€<br>- ì¼ë°˜í™” ëŠ¥ë ¥ í™•ì¸                                   |
|12. ë°°í¬            | - ì›¹ ì„œë¹„ìŠ¤(API) ë˜ëŠ” ì•±ì— ëª¨ë¸ í†µí•©<br>- ëª¨ë¸ì„ pickle, joblib ë“±ìœ¼ë¡œ ì €ì¥ í›„ ë¡œë“œ      |
|13. ëª¨ë‹ˆí„°ë§ & ìœ ì§€ë³´ìˆ˜| - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì¬í•™ìŠµ í•„ìš” ì‹œ ì—…ë°ì´íŠ¸<br>- ë°ì´í„° ë“œë¦¬í”„íŠ¸ íƒì§€ ë° ì¡°ì¹˜          |

## ë°ì´í„° ë‹¤ìš´ ë° ë¡œë“œ
from pathlib import Path
import pandas as pd
import tarfile
import urllib.request

def load_housing_data():
    tarball_path = Path("datasets/housing.tgz")
    if not tarball_path.is_file():
        Path("datasets").mkdir(parents=True, exist_ok=True)
        url = "https://github.com/ageron/data/raw/main/housing.tgz"
        urllib.request.urlretrieve(url, tarball_path)
    with tarfile.open(tarball_path) as housing_tarball:
        housing_tarball.extractall(path="datasets")
    
    return pd.read_csv(Path("datasets/housing/housing.csv"))

housing = load_housing_data()

## ë°ì´í„° íƒìƒ‰ ì‹œê°í™”
import matplotlib.pyplot as plt

housing.hist(bins=50, figsize=(12, 8))
plt.show()

## ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ í›ˆë ¨
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression

### ë°ì´í„° ë¶„ë¦¬
X = housing.drop("median_house_value", axis=1)
y = housing["median_house_value"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

### ë°ì´í„° ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

### ì„ í˜• íšŒê·€ ëª¨ë¸ í›ˆë ¨
model = LinearRegression()
model.fit(X_train_scaled, y_train)

### ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test_scaled)

## ëª¨ë¸ í‰ê°€
from sklearn.metrics import mean_squared_error

rmse = mean_squared_error(y_test, y_pred, squared=False)
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° RMSE: {rmse}")

# ë¨¸ì‹ ëŸ¬ë‹ì˜ ë¶„ë¥˜ ë°©ë²•

| ë¶„ë¥˜ ê¸°ì¤€           | ë¶„ë¥˜ ë°©ì‹                     | ì„¤ëª…                                                                 |
|----------------------|------------------------------|----------------------------------------------------------------------|
| **ì§€ë„ ë°©ì‹**         | - ì§€ë„ í•™ìŠµ (Supervised)      | ì…ë ¥ê³¼ ì •ë‹µ(ë ˆì´ë¸”) ì¡´ì¬. ì˜ˆ: íšŒê·€, ë¶„ë¥˜                              |
|                      | - ë¹„ì§€ë„ í•™ìŠµ (Unsupervised)  | ë ˆì´ë¸” ì—†ìŒ. ì˜ˆ: êµ°ì§‘, ì°¨ì› ì¶•ì†Œ                                     |
|                      | - ì¤€ì§€ë„ í•™ìŠµ (Semi-Supervised)| ì¼ë¶€ ë ˆì´ë¸”ë§Œ ìˆëŠ” ë°ì´í„°ë¡œ í•™ìŠµ                                      |
|                      | - ìê¸° ì§€ë„ í•™ìŠµ (Self-Supervised)| ì…ë ¥ìœ¼ë¡œë¶€í„° ë ˆì´ë¸” ìƒì„±í•´ í•™ìŠµ. ì˜ˆ: GPT ë“±                            |
|                      | - ê°•í™” í•™ìŠµ (Reinforcement)   | ë³´ìƒ/ë²Œì ì„ í†µí•´ ìµœì  ì •ì±…ì„ í•™ìŠµ                                     |
| **í•™ìŠµ ì‹œì **         | - ë°°ì¹˜ í•™ìŠµ (Batch)           | ì „ì²´ ë°ì´í„°ë¥¼ í•œêº¼ë²ˆì— í•™ìŠµ                                           |
|                      | - ì˜¨ë¼ì¸ í•™ìŠµ (Online)        | ë°ì´í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë°›ì•„ ì ì§„ì ìœ¼ë¡œ í•™ìŠµ                              |
| **ì¼ë°˜í™” ë°©ì‹**       | - ì‚¬ë¡€ ê¸°ë°˜ í•™ìŠµ (Instance-based) | í›ˆë ¨ ìƒ˜í”Œì„ ê¸°ì–µ, ìœ ì‚¬ë„ ë¹„êµë¡œ ì˜ˆì¸¡. ì˜ˆ: K-NN                        |
|                      | - ëª¨ë¸ ê¸°ë°˜ í•™ìŠµ (Model-based)| ëª¨ë¸ì„ ìˆ˜í•™ì ìœ¼ë¡œ ì¼ë°˜í™”í•´ì„œ ì˜ˆì¸¡. ì˜ˆ: ì„ í˜• íšŒê·€, ì‹ ê²½ë§ ë“±           |

# ğŸ“Œ MNIST ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
from sklearn.datasets import fetch_openml

## MNIST ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¡œë“œ
mnist = fetch_openml('mnist_784', as_frame=False)

## ì…ë ¥ ë°ì´í„°(X)ì™€ ë ˆì´ë¸”(y) ë¶„ë¦¬
X, y = mnist.data, mnist.target



# ğŸ“Œ ë°ì´í„°ì…‹ ë¶„ë¦¬ ë° ì‹œê°í™”
import matplotlib.pyplot as plt

## í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]

## ìˆ«ì ì´ë¯¸ì§€ í™•ì¸ í•¨ìˆ˜
def plot_digit(image_data):
    image = image_data.reshape(28, 28)
    plt.imshow(image, cmap="binary")
    plt.axis("off")
    plt.show()

## ìƒ˜í”Œ ìˆ«ì ì¶œë ¥
some_digit = X[0]
plot_digit(some_digit)

## ì‹¤ì œ ë ˆì´ë¸” í™•ì¸
print(y[0])  # '5'

î·›î·œî·™î·š

# ğŸ“Œ ì´ì§„ ë¶„ë¥˜ê¸°(SGDClassifier)
from sklearn.linear_model import SGDClassifier

## '5'ë¥¼ ê°ì§€í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ê¸° í•™ìŠµ
y_train_5 = (y_train == '5')  # '5'ë©´ True, ë‚˜ë¨¸ì§€ëŠ” False
y_test_5 = (y_test == '5')

sgd_clf = SGDClassifier(random_state=42)
sgd_clf.fit(X_train, y_train_5)

## ì˜ˆì¸¡ ì‹¤í–‰
print(sgd_clf.predict([some_digit]))  # True



# ğŸ“Œ ë‹¤ì¤‘ ë¶„ë¥˜ (OvR & OvO ì „ëµ)
from sklearn.svm import SVC
from sklearn.multiclass import OneVsRestClassifier

## SVC ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì¤‘ ë¶„ë¥˜ ìˆ˜í–‰
svm_clf = SVC(random_state=42)
svm_clf.fit(X_train[:2000], y_train[:2000])  # ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ í•™ìŠµ

## ì˜ˆì¸¡ ì‹¤í–‰
print(svm_clf.predict([some_digit]))  # ['5']

## OvR ì „ëµ ê°•ì œ ì ìš©
ovr_clf = OneVsRestClassifier(SVC(random_state=42))
ovr_clf.fit(X_train[:2000], y_train[:2000])

## ì˜ˆì¸¡ ì‹¤í–‰
print(ovr_clf.predict([some_digit]))  # ['5']

î·›î·œ

# ğŸ“Œ ì„±ëŠ¥ í‰ê°€ ë° êµì°¨ ê²€ì¦
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler

## ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ë° SGDClassifier í•™ìŠµ
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train.astype("float64"))

sgd_clf.fit(X_train_scaled, y_train)

## êµì°¨ ê²€ì¦ í‰ê°€
print(cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring="accuracy"))

î·™î·š

ì´ ì½”ë“œë“¤ì€ MNIST ë°ì´í„°ì…‹ì„ í™œìš©í•œ ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ í•™ìŠµ ê³¼ì •ì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤. í•„ìš”í•˜ì‹  ì¶”ê°€ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜Š


# SWM

| ê°œë…          | ì„¤ëª… |
|--------------|--------------------------------------------------------|
| **SVM(Support Vector Machine)** | ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ë¶„ë¥˜í•˜ëŠ” ê°•ë ¥í•œ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ |
| **ë¼ì§€ ë§ˆì§„ ë¶„ë¥˜** | ì„œë¡œ ë‹¤ë¥¸ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ ìµœëŒ€í•œ ë¶„ë¦¬í•˜ëŠ” ê²½ê³„ë¥¼ ì°¾ìŒ |
| **ì„œí¬íŠ¸ ë²¡í„°** | ê²°ì • ê²½ê³„ë¥¼ í˜•ì„±í•˜ëŠ” ì¤‘ìš”í•œ ë°ì´í„° í¬ì¸íŠ¸ |
| **í•˜ë“œ ë§ˆì§„ ë¶„ë¥˜** | ëª¨ë“  ìƒ˜í”Œì´ ë§ˆì§„ ë°–ì— ìˆë„ë¡ ê²°ì • ê²½ê³„ë¥¼ ì„¤ì • (ì´ìƒì¹˜ì— ë¯¼ê°) |
| **ì†Œí”„íŠ¸ ë§ˆì§„ ë¶„ë¥˜** | ë§ˆì§„ ë‚´ ìƒ˜í”Œì´ í—ˆìš©ë˜ë©°, ì¼ì • ìˆ˜ì¤€ì˜ ì˜¤ë¥˜ë¥¼ ê°ë‚´í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì„ |
| **C ê°’** | ë§ˆì§„ì„ ì¡°ì •í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° (ì‘ìœ¼ë©´ ë§ˆì§„ ë„“ê³ , í¬ë©´ ë§ˆì§„ ì¢ìŒ) |
| **ë¹„ì„ í˜• ë¶„ë¥˜** | ë°ì´í„°ë¥¼ ë³€í™˜í•˜ì—¬ ì„ í˜•ì ìœ¼ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ ë³€í˜• |
| **ì»¤ë„ íŠ¸ë¦­** | ë†’ì€ ì°¨ì›ì˜ ê³µê°„ì—ì„œ ë°ì´í„°ë¥¼ ë³€í™˜í•˜ì—¬ ì„ í˜•ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ê¸°ë²• |
| **ë‹¤í•­ì‹ ì»¤ë„** | ë‹¤í•­ì‹ì„ ì´ìš©í•˜ì—¬ ë°ì´í„° í¬ì¸íŠ¸ì˜ ë³€í™˜ì„ ìˆ˜í–‰ |
| **ê°€ìš°ìŠ¤ RBF ì»¤ë„** | ë°ì´í„° ê°„ì˜ ê±°ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì„±ì„ ë³€í™˜í•˜ì—¬ ë³µì¡í•œ ê²°ì • ê²½ê³„ë¥¼ ìƒì„± |
| **SVM íšŒê·€** | ë§ˆì§„ ì˜¤ë¥˜ ì•ˆì—ì„œ ê°€ì¥ ë§ì€ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” íšŒê·€ ëª¨ë¸ì„ ìƒì„± |
| **LinearSVC** | ì„ í˜• SVM ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ (ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ì í•©) |
| **SVR** | SVMì„ ì´ìš©í•œ íšŒê·€ ëª¨ë¸ |****

# ğŸ“Œ ì„ í˜• SVM ë¶„ë¥˜ - ë¶“ê½ƒ ë°ì´í„°ì…‹ í™œìš©
from sklearn.datasets import load_iris
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC

## ë°ì´í„° ë¡œë“œ
iris = load_iris(as_frame=True)
X = iris.data[["petal length (cm)", "petal width (cm)"]].values
y = (iris.target == 2)  # Iris-Virginica ê°ì§€

## ì„ í˜• SVM ëª¨ë¸ í•™ìŠµ
svm_clf = make_pipeline(StandardScaler(), LinearSVC(C=1, random_state=42))
svm_clf.fit(X, y)

## ì˜ˆì¸¡ ì‹¤í–‰
X_new = [[5.5, 1.7], [5.0, 1.5]]
print(svm_clf.predict(X_new))

î·›î·œî·™î·š

# ğŸ“Œ ë¹„ì„ í˜• SVM ë¶„ë¥˜ - ë‹¤í•­ì‹ ì»¤ë„ ì‚¬ìš©
from sklearn.datasets import make_moons
from sklearn.preprocessing import PolynomialFeatures
from sklearn.svm import SVC

## ë°ì´í„° ìƒì„±
X, y = make_moons(n_samples=100, noise=0.15, random_state=42)

## ë‹¤í•­ ì»¤ë„ SVM ëª¨ë¸ í•™ìŠµ
poly_kernel_svm_clf = make_pipeline(StandardScaler(),
                                    SVC(kernel="poly", degree=3, coef0=1, C=5))
poly_kernel_svm_clf.fit(X, y)

î·™î·š

# ğŸ“Œ ê°€ìš°ìŠ¤ RBF ì»¤ë„ì„ ì´ìš©í•œ ë¹„ì„ í˜• SVM ë¶„ë¥˜
from sklearn.svm import SVC

## RBF ì»¤ë„ì„ ì‚¬ìš©í•œ SVM ëª¨ë¸
rbf_kernel_svm_clf = make_pipeline(StandardScaler(), 
                                   SVC(kernel="rbf", gamma=5, C=0.001))
rbf_kernel_svm_clf.fit(X, y)



# ğŸ“Œ SVMì„ í™œìš©í•œ íšŒê·€ ëª¨ë¸ í•™ìŠµ
from sklearn.svm import SVR
import numpy as np

## ë°ì´í„° ìƒì„±
X = np.linspace(-1, 1, 100).reshape(-1, 1)
y = X**2 + np.random.randn(100, 1) * 0.1  # 2ì°¨ í•¨ìˆ˜ ë°ì´í„°

## SVM íšŒê·€ ëª¨ë¸ í•™ìŠµ
svm_poly_reg = make_pipeline(StandardScaler(),
                            SVR(kernel="poly", degree=2, C=0.01, epsilon=0.1))
svm_poly_reg.fit(X, y.ravel())

î·™î·š

ì´ë ‡ê²Œ ì •ë¦¬í•˜ë©´ ì½”ë“œ ë¶€ë¶„ë§Œ ë°°ê²½ìƒ‰ì´ ë‹¤ë¥´ê²Œ í‘œì‹œë˜ë¯€ë¡œ ê°€ë…ì„±ì´ ì¢‹ì„ ê±°ì˜ˆìš”.
ì¶”ê°€ì ìœ¼ë¡œ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜Š

# ì‹¤ìŠµì½”ë“œ
## ğŸ“Œ ğŸš– íƒì‹œ ìš”ê¸ˆ ì˜ˆì¸¡ ì‹¤ìŠµ ì½”ë“œ
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression

### ê°€ìƒì˜ íƒì‹œ ìš”ê¸ˆ ë°ì´í„° ìƒì„±
data = {"Distance": [1, 5, 10, 15, 20], "Fare": [2000, 7000, 12000, 17000, 22000]}
df = pd.DataFrame(data)

### ë°ì´í„° ë¶„ë¦¬
X = df[["Distance"]]
y = df[["Fare"]]

### ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ
model = LinearRegression()
model.fit(X, y)

### ìƒˆë¡œìš´ ê±°ë¦¬(3.5km)ì— ëŒ€í•œ ì˜ˆìƒ ìš”ê¸ˆ ì˜ˆì¸¡
X_test = [[3.5]]
predicted_fare = model.predict(X_test)
print(f"3.5km ì´ë™ ì‹œ ì˜ˆìƒ ìš”ê¸ˆ: {predicted_fare[0][0]}ì›")

î·›î·œî·™î·š

## ğŸ“Œ ğŸ® FIFA ì„ ìˆ˜ í¬ì§€ì…˜ ì˜ˆì¸¡ ì½”ë“œ
ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ í•™ìŠµ
import pandas as pd
import pickle
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

### ë°ì´í„° ë¡œë“œ
df = pd.read_csv("./data/fifa_data.csv")

### í•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ ë° ì „ì²˜ë¦¬
df = df[['Name', 'Position', 'Crossing', 'Finishing', 'HeadingAccuracy',
         'ShortPassing', 'Volleys', 'Dribbling', 'BallControl', 'Acceleration',
         'SprintSpeed', 'Interceptions', 'Positioning', 'Vision', 'Penalties',
         'Marking', 'StandingTackle', 'SlidingTackle', 'GKDiving', 'GKHandling',
         'GKKicking', 'GKPositioning', 'GKReflexes']]
df.dropna(inplace=True)

### ë°ì´í„° ë¶„í• 
X = df.drop(['Name', 'Position'], axis=1)
y = df["Position"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

### ë°ì´í„° ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

### SVM ëª¨ë¸ í•™ìŠµ
svm_clf = SVC(kernel="rbf", C=10, gamma=0.0001)
svm_clf.fit(X_train_scaled, y_train)

### ì˜ˆì¸¡ ë° í‰ê°€
y_pred = svm_clf.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
print(f"FIFA í¬ì§€ì…˜ ì˜ˆì¸¡ ì •í™•ë„: {accuracy:.2f}")

î·›î·œî·™î·š

ì´ë ‡ê²Œ ì •ë¦¬í•˜ë©´ ì½”ë“œ ë¶€ë¶„ë§Œ ë°°ê²½ìƒ‰ì´ ë‹¤ë¥´ê²Œ í‘œì‹œë˜ì–´ ê°€ë…ì„±ì´ ì¢‹ì„ ê±°ì˜ˆìš”. ì¶”ê°€ì ìœ¼ë¡œ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜Š


# âœ… ì •ë¦¬ ìš”ì•½
ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ë¥¼ í†µí•œ í•™ìŠµì´ë©°, ì „ì²˜ë¦¬ â†’ ëª¨ë¸ í›ˆë ¨ â†’ í‰ê°€ â†’ ë°°í¬ ìˆœì„œ

ì§€ë„ í•™ìŠµì´ ì¤‘ì‹¬ (ë¶„ë¥˜, íšŒê·€)

SVM, ì„ í˜• íšŒê·€, ëœë¤ í¬ë ˆìŠ¤íŠ¸, kNN ë“± ì•Œê³ ë¦¬ì¦˜ ì´í•´

ì •í™•ë„ë¿ ì•„ë‹ˆë¼ ì •ë°€ë„Â·ì¬í˜„ìœ¨Â·F1 ì ìˆ˜ í™œìš©í•œ í‰ê°€ í•„ìˆ˜

ì‹¤ìŠµ ì˜ˆì œëŠ” ì½”ë“œ ì¤‘ì‹¬ìœ¼ë¡œ ì•”ê¸°ë³´ë‹¨ ì‹¤í–‰í•˜ë©° ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”
